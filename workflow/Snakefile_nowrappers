import os
import snakemake.io
import glob
import pandas as pd
#import snakemake_wrapper_utils

# Snakemake tutorial
# https://snakemake.readthedocs.io/en/stable/tutorial/basics.html
# https://stackoverflow.com/questions/56271154/use-snakemake-pair-end-bwa-alignment

print(sys.path)
# Reference to config:
# https://github.com/snakemake-workflows/dna-seq-gatk-variant-calling/blob/main/workflow/rules/common.smk


###### Config file and sample sheets #####
configfile: "config/config.yaml"

# Load the samples table:
table=pd.read_csv("config/table_reads.tsv", sep=r'\s+',  header=0, index_col=False)

# Use the samples table to make lists of samples names/lists:
SAMPLES=table['read_ID'].to_list()
POPULATIONS=list(set(table['Population'].to_list()))
READS=["1","2"]

print(SAMPLES)
print(POPULATIONS)
print(READS)


# The first rule (here rule all) specifies the files that you would like to create during your snakemake workflow.

rule all:
    input:
        'plots/plot_heterozygosity_FROH_regline.png',
        'plots/plot_SROH_NROH_FROH.png',
        'plots/plot_SROH_NROH_Population.png',
        'plots/plot_ROH_length_hist.png',
        'plots/plot_ROH_SNPs_hist.png',
        'calls/all.vcf',
        'heterozygosity/matrix_het_angsd.tsv',
        expand('logs/repair/{sample}_read_counts.txt', sample=SAMPLES),
        expand("trimmed/{sample}_1_paired.fastq.gz", sample=SAMPLES),
        expand("trimmed/{sample}_2_paired.fastq.gz", sample=SAMPLES)





# ALIGNMENT:

rule fastqc:
	input:
		expand("reads/{sample}_{read}.fq.gz", sample=SAMPLES, read=READS),

	output:
		html="qc/fastqc/{sample}.html",
		zip="qc/fastqc/{sample}_fastqc.zip" # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename
	params:
		extra = "--quiet"
	log:
		"logs/fastqc/{sample}.log"
	threads: 1
	resources:
		mem_mb = 1024
	wrapper:
		"v7.2.0/bio/fastqc"


# Add this rule after the fastqc rule
rule trimmomatic_pe:
	input:
		r1="reads/{sample}_1.fq.gz",
		r2="reads/{sample}_2.fq.gz"
	output:
		r1="trimmed/{sample}_1_paired.fastq.gz",
		r2="trimmed/{sample}_2_paired.fastq.gz",
		r1_unpaired="trimmed/{sample}_1_unpaired.fastq.gz",
		r2_unpaired="trimmed/{sample}_2_unpaired.fastq.gz"
	log:
		"logs/trimmomatic/{sample}.log"
	params:
        # Adjust these parameters as needed
		#extra="ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36"
		extra="ILLUMINACLIP:/home/tmichel/Trimmomatic-0.39/adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36"
	threads: 4
	resources:
		mem_mb = 1024
	shell:
		"""
		trimmomatic PE \
		-threads {threads} \
		{input.r1} {input.r2} \
		{output.r1} {output.r2} \
		{output.r1_unpaired} {output.r2_unpaired} \
		{params.extra} \
		2> {log}
		"""

rule repair_reads:
    input:
        r1="trimmed/{sample}_1_paired.fastq.gz",
        r2="trimmed/{sample}_2_paired.fastq.gz"
    output:
        r1_repaired="trimmed/{sample}_1_paired.repair.fastq.gz",
        r2_repaired="trimmed/{sample}_2_paired.repair.fastq.gz",
        singletons="trimmed/{sample}_singletons.repair.fastq.gz"
    log:
        "logs/repair/{sample}.log"
    threads: 2
    shell:
        """
        repair.sh \
            in1={input.r1} \
            in2={input.r2} \
            out1={output.r1_repaired} \
            out2={output.r2_repaired} \
            outs={output.singletons} \
            overwrite=true \
            2> {log}
        """


rule count_reads:
    input:
        r1="trimmed/{sample}_1_paired.fastq.gz",
        r2="trimmed/{sample}_2_paired.fastq.gz",
        r1_repaired="trimmed/{sample}_1_paired.repair.fastq.gz",
        r2_repaired="trimmed/{sample}_2_paired.repair.fastq.gz"
    output:
        report="logs/repair/{sample}_read_counts.txt"
    run:
        def count_reads(fq):
            import subprocess
            cmd = f"zcat {fq} | wc -l"
            out = subprocess.check_output(cmd, shell=True)
            return int(out.strip()) // 4

        original_r1 = count_reads(input.r1)
        original_r2 = count_reads(input.r2)
        repaired_r1 = count_reads(input.r1_repaired)
        repaired_r2 = count_reads(input.r2_repaired)

        with open(output.report, "w") as f:
            f.write(f"Sample: {wildcards.sample}\n")
            f.write(f"Original R1 reads: {original_r1}\n")
            f.write(f"Original R2 reads: {original_r2}\n")
            f.write(f"Repaired R1 reads: {repaired_r1}\n")
            f.write(f"Repaired R2 reads: {repaired_r2}\n")
            f.write(f"Reads lost in R1: {original_r1 - repaired_r1}\n")
            f.write(f"Reads lost in R2: {original_r2 - repaired_r2}\n")



rule bwa_index:
	input:
		config["reference"]
		#"{genome}.fasta", 
	output:
		idx=multiext("{genome}", ".amb", ".ann", ".bwt", ".pac", ".sa"),
	log:
		"logs/bwa_index/{genome}.log",
	params:
		algorithm="bwtsw",
	wrapper:
		"v7.2.0/bio/bwa/index"

# https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/bwa/mem.html
#rule bwa_mem:
#	input:
#		reads=["trimmed/{sample}_1_paired.fastq.gz", "trimmed/{sample}_2_paired.fastq.gz"],
#		idx=multiext("genome", ".amb", ".ann", ".bwt", ".pac", ".sa"),
#	output:
#		"mapped/{sample}.bam",
#	log:
#		"logs/bwa_mem/{sample}.log",
#	params:
#		extra=r"-R '@RG\tID:{sample}\tSM:{sample}'",
#		sorting="none",  # Can be 'none', 'samtools' or 'picard'.
#		sort_order="queryname",  # Can be 'queryname' or 'coordinate'.
#		sort_extra="",  # Extra args for samtools/picard.
#	threads: 8
#	wrapper:
 #       	"v7.2.0/bio/bwa/mem"

rule bwa_mem:
    input:
        fq1="trimmed/{sample}_1_paired.repair.fastq.gz",
        fq2="trimmed/{sample}_2_paired.repair.fastq.gz",
        idx=["genome.amb", "genome.ann", "genome.bwt", "genome.pac", "genome.sa"]
    output:
        bam="mapped/{sample}.bam"
    log:
        "logs/bwa_mem/{sample}.log"
    params:
        rg="@RG\\tID:{sample}\\tSM:{sample}"  # Escaped tabs for bash
    threads: 8
    shell:
        """
        bwa mem -t {threads} -R '{params.rg}' genome {input.fq1} {input.fq2} 2> {log} 
        """



# CALLING VARIANTS

# https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/samtools/sort.html
#rule samtools_sort:
#    input:
#        "mapped/{sample}.bam",
#    output:
#        "mapped/{sample}.sorted.bam",
#    log:
#        "{sample}.log",
#    params:
#        extra="-m 4G",
#    threads: 8
#    wrapper:
#        "v7.2.0/bio/samtools/sort"

rule samtools_sort:
    input:
        "mapped/{sample}.bam"
    output:
        "mapped/{sample}.sorted.bam"
    log:
        "logs/samtools_sort/{sample}.log"
    params:
        extra="-m 4G"
    threads: 8
    shell:
        """
        bwa mem -t {threads} -R '{params.rg}' genome {input.fq1} {input.fq2} 2> {log} |
        samtools view -@ {threads} -Sb -o {output.bam} -
        """
# https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/samtools/
#rule samtools_index:
#    input:
#        "mapped/{sample}.sorted.bam",
#    output:
#        "mapped/{sample}.sorted.bam.bai",
#    log:
#        "logs/samtools_index/{sample}.log",
#    params:
#        extra="",  # optional params string
#    threads: 4  # This value - 1 will be sent to -@
#    wrapper:
#        "v7.2.0/bio/samtools/index"

rule samtools_index:
    input:
        "mapped/{sample}.sorted.bam"
    output:
        "mapped/{sample}.sorted.bam.bai"
    log:
        "logs/samtools_index/{sample}.log"
    params:
        extra=""
    threads: 4
    shell:
        """
        samtools index {params.extra} -@ {threads} {input} 2> {log}
        """



# https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/gatk/haplotypecaller.html
#rule haplotype_caller_gvcf:
#    input:
#        # single or list of bam files
#        bam="mapped/{sample}.sorted.bam",
#        ref=config["reference"],
#        idx="mapped/{sample}.sorted.bam.bai"
#        # known="dbsnp.vcf"  # optional
#    output:
#        gvcf="calls/{sample}.g.vcf",
#    #       bam="{sample}.assemb_haplo.bam",
#    log:
#        "logs/gatk/haplotypecaller/{sample}.log",
#    params:
#        extra="",  # optional
#        java_opts="",  # optional
#    threads: 4
#    resources:
#        mem_mb=1024,
#    wrapper:
#        "v7.2.0/bio/gatk/haplotypecaller"

rule haplotype_caller_gvcf:
    input:
        bam="mapped/{sample}.sorted.bam",
        idx="mapped/{sample}.sorted.bam.bai",
        ref=config["reference"]
    output:
        gvcf="calls/{sample}.g.vcf"
    log:
        "logs/gatk/haplotypecaller/{sample}.log"
    params:
        extra="",
        java_opts="-Xmx4g"  # You can modify based on memory needs
    threads: 4
    resources:
        mem_mb=1024
    shell:
        """
        gatk --java-options "{params.java_opts}" HaplotypeCaller \
            -R {input.ref} \
            -I {input.bam} \
            -O {output.gvcf} \
            -ERC GVCF \
            {params.extra} \
            2> {log}
        """



rule produce_interval_list:
    input: 
       ref=config["reference"]
    output:
       "intervals_edit.list"
    shell: 
       "cat {input.ref} | grep '>' | sed 's/>//' > {output}"



# https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/gatk/genomicsdbimport.html
#rule genomics_db_import:
#    input:
#        gvcfs=expand("calls/{sample}.g.vcf", sample=SAMPLES),
#        inter="intervals_edit.list",
#    output:
#        db=directory("db"),
#    log:
#        "logs/gatk/genomicsdbimport.log",
#    params:
#        intervals="intervals_edit.list",
#        db_action="create",  # optional
#        extra="",  # optional
#        java_opts="",  # optional
#    threads: 2
#    resources:
#        mem_mb=lambda wildcards, input: max([input.size_mb * 1.6, 200]),
#    wrapper:
#        "v7.2.0/bio/gatk/genomicsdbimport"

rule genomics_db_import:
    input:
        gvcfs=expand("calls/{sample}.g.vcf", sample=SAMPLES),
        inter="intervals_edit.list"
    output:
        db=directory("db")
    log:
        "logs/gatk/genomicsdbimport.log"
    params:
        intervals="intervals_edit.list",
        db_action="create",  # Optional: can be omitted
        extra="",
        java_opts="-Xmx4g"  # Or adjust depending on memory
    threads: 2
    resources:
        mem_mb=lambda wildcards, input: max([input.size_mb * 1.6, 200])
    shell:
        """
        gatk --java-options "{params.java_opts}" GenomicsDBImport \
            --genomicsdb-workspace-path {output.db} \
            --intervals {params.intervals} \
            {params.extra} \
            {join(" ", ["--variant " + gvcf for gvcf in input.gvcfs])} \
            2> {log}
        """





# https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/gatk/genotypegvcfs.html
#rule genotype_gvcfs:
#    input:
#        genomicsdb="db",  # combined gvcf over multiple samples
#    # N.B. gvcf or genomicsdb must be specified
#    # in the latter case, this is a GenomicsDB data store
#        ref=config["reference"],
#    output:
#        vcf="calls/all.vcf",
#    log:
#        "logs/gatk/genotypegvcfs.log"
#    params:
#        extra="",  # optional
#        java_opts="", # optional
#    resources:
#        mem_mb=1024
#    wrapper:
#        "v7.2.0/bio/gatk/genotypegvcfs"

rule genotype_gvcfs:
    input:
        genomicsdb="db",  # GenomicsDB workspace
        ref=config["reference"]
    output:
        vcf="calls/all.vcf"
    log:
        "logs/gatk/genotypegvcfs.log"
    params:
        extra="",
        java_opts="-Xmx4g"  # You can customize this
    resources:
        mem_mb=1024
    shell:
        """
        gatk --java-options "{params.java_opts}" GenotypeGVCFs \
            -R {input.ref} \
            -V gendb://{input.genomicsdb} \
            -O {output.vcf} \
            {params.extra} \
            2> {log}
        """



# PLINK ROH estimation:
rule plink_ROH_estimation:
    input:
       "calls/all.vcf",
    output:
       "plink/all.hom",
    shell:
        "plink --vcf calls/all.vcf --homozyg --out plink/all --allow-extra-chr --no-parents --no-sex --no-pheno --homozyg-window-snp 50 --homozyg-snp 50 --homozyg-window-missing 3 --homozyg-kb 1 --homozyg-density 1000 --const-fid 0 ; "



## Calculation minimal number of SNPs to consider a ROH:

# Genome length:
rule genome_length:
    input:
       ref=config["reference"],
    output:
       "genofreq/size_genome.txt",
    shell:
       "python workflow/script_genome_size.py {input.ref}"


# Make the genofreq table:
rule genofreq:
    input:
       "calls/all.vcf",
    output:
       "genofreq/geno_freq_all.csv",
       expand("genofreq/geno_freq_{populations}.csv", populations=POPULATIONS),
    shell:
       "sh workflow/script_genofreq.sh calls/all.vcf"

# Eventually, calculate minimal number SNPs:
rule min_nbr_SNPs_ROH:
    input:
       expand("genofreq/geno_freq_{populations}.csv", populations=POPULATIONS),
       "genofreq/size_genome.txt",
    output:
       "genofreq/list_min_number_het.txt",
    shell:
       "python workflow/script_minimum_number_SNPs_for_ROH.py"

# Calculate the heterozygosity matrix:
rule heterozygosity:
    input:
       expand("mapped/{sample}.sorted.bam", sample=SAMPLES),
       ref=config["reference"],
    output:
       "heterozygosity/matrix_het_angsd.tsv",
       expand("heterozygosity/{sample}.ml", sample=SAMPLES),
    shell:
       "sh workflow/script_het_angsd.sh {input.ref}"

# Calculate the angsd final heterozygosity
rule comp_angsd_het:
    input:
       expand("heterozygosity/{sample}.ml", sample=SAMPLES),
    output:
       "heterozygosity/heterozygosity_results_angsd.csv"
    shell:
       "python workflow/script_extract_het.py"

# Make the matrix with SROH, NROH, FROH:
rule SROH_NROH_FROH_het:
    input:
       "genofreq/size_genome.txt",
       "genofreq/list_min_number_het.txt",
       "plink/all.hom",
       "heterozygosity/heterozygosity_results_angsd.csv",
    output:
       "output/matrix_ROH.csv",
    shell:
       "python workflow/script_SROH_NROH_FROH_het.py"

# Make the ROH distribution plots:
rule ROH_distribution_plots:
    input:
       "plink/all.hom",
    output:
       'plots/plot_ROH_length_hist.png',
       'plots/plot_ROH_SNPs_hist.png',
    shell:
       "python workflow/script_ROH_distribution.py"

# Make the SROH, NROH, FROH, het plots:
rule NROH_SROH_FROH_het_plots:
    input:
       "output/matrix_ROH.csv",
    output:
       'plots/plot_heterozygosity_FROH_regline.png',
       'plots/plot_SROH_NROH_FROH.png',
       'plots/plot_SROH_NROH_Population.png',
    shell:
       "python workflow/script_NROH_SROH_FROH_het_plots.py"
